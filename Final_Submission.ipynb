{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0254f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vinay\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vinay\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vinay\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vinay\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\vinay\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vinay\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "10/10 [==============================] - 4s 235ms/step - loss: 0.7017 - accuracy: 0.5200 - val_loss: 0.6284 - val_accuracy: 0.4800\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.5892 - accuracy: 0.6867 - val_loss: 0.5013 - val_accuracy: 0.8133\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.4532 - accuracy: 0.8300 - val_loss: 0.4018 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.3047 - accuracy: 0.9000 - val_loss: 0.2171 - val_accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.2548 - accuracy: 0.9133 - val_loss: 0.1861 - val_accuracy: 0.9467\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.2123 - accuracy: 0.9333 - val_loss: 0.1770 - val_accuracy: 0.9467\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 0.1860 - accuracy: 0.9400 - val_loss: 0.7027 - val_accuracy: 0.6933\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 0.3831 - accuracy: 0.8367 - val_loss: 0.2209 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 0.2152 - accuracy: 0.9367 - val_loss: 0.1683 - val_accuracy: 0.9467\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 0.2005 - accuracy: 0.9367 - val_loss: 0.2066 - val_accuracy: 0.9467\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1781 - accuracy: 0.9600\n",
      "Test Accuracy: 0.9599999785423279\n",
      "Full Image Path: CNR-EXT_FULL_IMAGE_1000x750/FULL_IMAGE_1000x750/SUNNY/2015-11-12/camera4/2015-11-12_1116.jpg\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Image with Boxes saved at: output_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "\n",
    "# Loading the dataset\n",
    "path_to_data = \"CNRPark+EXT.csv\"\n",
    "data = pd.read_csv(path_to_data, low_memory=False)\n",
    "\n",
    "# Taking a smaller subset of the data for testing\n",
    "data_subset = data.sample(n=500, random_state=42)\n",
    "\n",
    "# Extracting features (images) and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for index, row in data_subset.iterrows():\n",
    "    image_path = row['image_url']\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Checking if the image is loaded successfully\n",
    "    if image is not None:\n",
    "        # Resizing the image for consistency\n",
    "        image = cv2.resize(image, (100, 100))\n",
    "\n",
    "        # Checking if the resized image has valid dimensions\n",
    "        if image.shape == (100, 100):\n",
    "            features.append(image)\n",
    "            labels.append(row['occupancy'])\n",
    "        else:\n",
    "            print(f\"Invalid dimensions after resizing for image: {image_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Normalizing the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Building a larger CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the larger model\n",
    "model.fit(x_train.reshape(-1, 100, 100, 1), y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluating the larger model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test.reshape(-1, 100, 100, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "# Choosing a random full-scale image from the dataset\n",
    "random_index = np.random.randint(0, len(data))\n",
    "folder = \"CNR-EXT_FULL_IMAGE_1000x750/FULL_IMAGE_1000x750\"\n",
    "weather_initial = data.iloc[random_index]['weather']\n",
    "weather_mapping = {'S': 'SUNNY', 'R': 'RAINY', 'O': 'OVERCAST'}\n",
    "weather = weather_mapping.get(weather_initial, 'UNKNOWN')\n",
    "\n",
    "capt_date = f\"{data.iloc[random_index]['year']}-{data.iloc[random_index]['month']:02d}-{data.iloc[random_index]['day']:02d}\"\n",
    "cam_id = f\"camera{str(int(data.iloc[random_index]['camera']))}\"  # Ensure the camera value is treated as a string\n",
    "capt_time = f\"{data.iloc[random_index]['hour']:02d}{data.iloc[random_index]['minute']:02d}\"\n",
    "\n",
    "full_image_path = f\"{folder}/{weather}/{capt_date}/{cam_id}/{capt_date}_{capt_time}.jpg\"\n",
    "\n",
    "print(\"Full Image Path:\", full_image_path)\n",
    "\n",
    "\n",
    "# Reading the corresponding CSV file for the selected cam_id\n",
    "csv_filename = f\"{cam_id}.csv\"\n",
    "csv_path = os.path.join(\"C:\\\\Users\\\\vinay\\\\Downloads\\\\Dataset_CV_Final_Project\\\\CNR-EXT_FULL_IMAGE_1000x750\", csv_filename)\n",
    "patch_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Loading the image\n",
    "full_image = cv2.imread(full_image_path)\n",
    "\n",
    "\n",
    "# Drawing red and green boxes based on patch information\n",
    "for index, patch_info in patch_data.iterrows():\n",
    "    slot_id = patch_info['SlotId']\n",
    "    \n",
    "    # Rescaling the bounding box coordinates to match the current resolution\n",
    "    x = int(patch_info['X'] * (1000 / 2592))\n",
    "    y = int(patch_info['Y'] * (750 / 1944))\n",
    "    w = int(patch_info['W'] * (1000 / 2592))\n",
    "    h = int(patch_info['H'] * (750 / 1944))\n",
    "    \n",
    "    # Ensuring the rescaled region of interest is within the image bounds\n",
    "    if y < full_image.shape[0] and x < full_image.shape[1] and y + h < full_image.shape[0] and x + w < full_image.shape[1]:\n",
    "        # Check if the slot is occupied (1) or vacant (0)\n",
    "        roi = cv2.resize(full_image[y:y+h, x:x+w], (100, 100))\n",
    "        roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)  # Explicitly converting to single-channel\n",
    "        if model.predict(np.expand_dims(roi_rgb, axis=0)) > 0.5:\n",
    "            color = (0, 0, 255)  # red for occupied\n",
    "        else:\n",
    "            color = (0, 255, 0)  # green for vacant\n",
    "        cv2.rectangle(full_image, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "# Saving the resulting image\n",
    "output_image_path = \"output_image.jpg\"\n",
    "cv2.imwrite(output_image_path, full_image)\n",
    "\n",
    "# Displaying the path to the saved image\n",
    "print(\"Image with Boxes saved at:\", output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70048df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72e146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
